{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653883d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate https://storage.googleapis.com/emcassavadata/cassavaleafdata.zip \\\n",
    "    -O ./cassavaleafdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip cassavaleafdata.zip\n",
    "!rm cassavaleafdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fc9fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17ad78",
   "metadata": {},
   "source": [
    "HANDLING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b272b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {\n",
    "    \"train\": \"./cassavaleafdata/train\",\n",
    "    \"valid\": \"./cassavaleafdata/validation\",\n",
    "    \"test\": \"./cassavaleafdata/test\",\n",
    "}\n",
    "\n",
    "# Load image from path\n",
    "def loader(path):\n",
    "    return Image.open(path)\n",
    "\n",
    "img_size = 150\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    root=data_paths[\"train\"],\n",
    "    loader=loader,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "valid_data = datasets.ImageFolder(\n",
    "    root=data_paths[\"valid\"],\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=data_paths[\"test\"],\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "\n",
    "valid_dataloader = data.DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533a192",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aa3097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=6,\n",
    "            kernel_size=5,\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.fc_1 = nn.Linear(16 * 35 * 35, 120)\n",
    "        self.fc_2 = nn.Linear(120, 84)\n",
    "        self.fc_3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.avgpool1(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.avgpool2(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.flatten(outputs)\n",
    "        outputs = self.fc_1(outputs)\n",
    "        outputs = self.fc_2(outputs)\n",
    "        outputs = self.fc_3(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5d554",
   "metadata": {},
   "source": [
    "UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f264902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(\n",
    "    model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50\n",
    "):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {idx:5d}/{len(train_dataloader):5d} batches | accuracy {(total_acc / total_count):8.3f}\"\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "        epoch_acc = total_acc / total_count\n",
    "        epoch_loss = sum(losses) / len(losses)\n",
    "        return epoch_acc, epoch_loss\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, criterion, device, valid_dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6d0e5",
   "metadata": {},
   "source": [
    "TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c62da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| End of epoch   1 | Time: 10.12s | Train Accuracy    0.113 | Train loss    1.609| Valid Accuracy    0.470 | Valid loss    1.537\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   2 | Time: 11.42s | Train Accuracy    0.539 | Train loss    1.501| Valid Accuracy    0.470 | Valid loss    1.478\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   3 | Time:  8.47s | Train Accuracy    0.449 | Train loss    1.459| Valid Accuracy    0.470 | Valid loss    1.440\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   4 | Time:  7.40s | Train Accuracy    0.484 | Train loss    1.376| Valid Accuracy    0.470 | Valid loss    1.425\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   5 | Time:  9.56s | Train Accuracy    0.438 | Train loss    1.395| Valid Accuracy    0.470 | Valid loss    1.434\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   6 | Time: 10.69s | Train Accuracy    0.449 | Train loss    1.350| Valid Accuracy    0.470 | Valid loss    1.454\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   7 | Time:  9.37s | Train Accuracy    0.480 | Train loss    1.313| Valid Accuracy    0.470 | Valid loss    1.481\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   8 | Time:  8.02s | Train Accuracy    0.512 | Train loss    1.320| Valid Accuracy    0.470 | Valid loss    1.504\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   9 | Time: 11.04s | Train Accuracy    0.488 | Train loss    1.348| Valid Accuracy    0.470 | Valid loss    1.518\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  10 | Time: 10.11s | Train Accuracy    0.496 | Train loss    1.337| Valid Accuracy    0.470 | Valid loss    1.523\n",
      "-----------------------------------------------------------\n",
      "Test accuracy: 0.470026525198939 | test loss: 1.5331208258867264\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(train_data.classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lenet_model = LeNetClassifier(NUM_CLASSES)\n",
    "lenet_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 2e-4\n",
    "optimizer = optim.Adam(lenet_model.parameters(), learning_rate)\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = \"./model\"\n",
    "\n",
    "train_accs, train_losses = [], []\n",
    "eval_accs, eval_losses = [], []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # Training\n",
    "    train_acc, train_loss = train(\n",
    "        lenet_model, optimizer, criterion, train_dataloader, device, epoch, log_interval=10\n",
    "    )\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Evaluation\n",
    "    eval_acc, eval_loss = evaluate(lenet_model, criterion, device, valid_dataloader)\n",
    "    eval_accs.append(eval_acc)\n",
    "    eval_losses.append(eval_loss)\n",
    "\n",
    "    # Save best model\n",
    "    if eval_loss < best_loss_eval:\n",
    "        torch.save(lenet_model.state_dict(), save_model + \"/lenet_model.pt\")\n",
    "\n",
    "    # Print loss, acc and epoch\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        f\"| End of epoch {epoch:3d} | Time: {time.time() - epoch_start_time:5.2f}s | Train Accuracy {train_acc:8.3f} | Train loss {train_loss:8.3f}\"\n",
    "        f\"| Valid Accuracy {eval_acc:8.3f} | Valid loss {eval_loss:8.3f}\"\n",
    "    )\n",
    "    print(\"-\" * 59)\n",
    "\n",
    "    # Load best model\n",
    "    lenet_model.load_state_dict(torch.load(save_model + \"/lenet_model.pt\"))\n",
    "    lenet_model.eval()\n",
    "\n",
    "# Evaluate on test dataset\n",
    "test_dataloader = data.DataLoader(test_data, batch_size=256)\n",
    "test_acc, test_loss = evaluate(lenet_model, criterion, device, test_dataloader)\n",
    "print(f\"Test accuracy: {test_acc} | test loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio-hw2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
